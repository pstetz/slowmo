{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _files_exist(folder, filenames):\n",
    "    for filename in filenames:\n",
    "        filepath = join(folder, filename)\n",
    "        if not os.path.isfile(filepath):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def _has_structural(subject_path):\n",
    "    needed = [\"gm_probseg.nii.gz\", \"subject_to_MNI_warp.nii.gz\"]\n",
    "    return _files_exist(join(subject_path, \"structural\"), needed)\n",
    "\n",
    "def _get_tasks(subject_path):\n",
    "    tasks = glob(join(subject_path, \"*\"))\n",
    "    tasks = [os.path.basename(task_path) for task_path in tasks]\n",
    "    return [task for task in tasks if task != \"structural\"]\n",
    "\n",
    "def _validate_subject_task(subject_path, task):\n",
    "    needed = [\"onsets.csv\", \"normalized.nii.gz\"]\n",
    "    if not _has_structural(subject_path):\n",
    "        return False\n",
    "    return _files_exist(join(subject_path, task), needed)\n",
    "\n",
    "def _map_time_session(time_session):\n",
    "    _map = {\"000\": \"s1\", \"2MO\": \"s2\", \"6MO\": \"s3\", \"12MO\": \"s4\", \"24MO\": \"s5\"}\n",
    "    return _map[time_session]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if files exist\n",
    "\n",
    "Need fMRI data, onsets, and structurals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Volumes/hd_4tb/raw\"\n",
    "rows = list()\n",
    "\n",
    "for project_path in glob(join(root, \"*\")):\n",
    "    project = os.path.basename(project_path)\n",
    "    for time_path in glob(join(project_path, \"*\")):\n",
    "        time_session = os.path.basename(time_path)\n",
    "        for subject_path in glob(join(time_path, \"*\")):\n",
    "            subject = os.path.basename(subject_path)\n",
    "            tasks = _get_tasks(subject_path)\n",
    "            for task in tasks:\n",
    "                valid = _validate_subject_task(subject_path, task)\n",
    "                row = {\n",
    "                    \"project\": project,\n",
    "                    \"time_session\": _map_time_session(time_session),\n",
    "                    \"subject\": subject,\n",
    "                    \"task\": task,\n",
    "                    \"data_exists\": valid\n",
    "                }\n",
    "                rows.append(row)\n",
    "\n",
    "files = pd.DataFrame(rows)\n",
    "print(files.shape)\n",
    "files = files[files.data_exists]\n",
    "files.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_csv = \"/Volumes/hd_4tb/project/movement/all.csv\"\n",
    "movement = pd.read_csv(movement_csv)\n",
    "movement.dropna(inplace=True)\n",
    "df = pd.merge(files, movement, on=[\"project\", \"subject\", \"time_session\", \"task\"], how=\"left\")\n",
    "df.dropna(inplace=True)\n",
    "df = df[df.discarded_vols < 38]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicom info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_csv = \"/Volumes/hd_4tb/project/info.csv\"\n",
    "info = pd.read_csv(info_csv)\n",
    "info.time_session = info.time_session.map({\"000\": \"s1\", \"2MO\": \"s2\", \"6MO\": \"s3\", \"12MO\": \"s4\", \"24MO\": \"s5\"})\n",
    "full = pd.merge(df, info, on=[\"project\", \"subject\", \"time_session\", \"task\"], how=\"left\")\n",
    "full = full[((full.age.notnull()) & (full.gender.notnull()))]\n",
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.to_csv(\"/Volumes/hd_4tb/project/clean.csv\", index=False)\n",
    "full.task.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_task(task, name):\n",
    "    if task == \"gonogo\" and task == name:\n",
    "        return True\n",
    "    elif task == \"conscious\" and task == name:\n",
    "        return True\n",
    "    elif task == \"nonconscious\" and task == name:\n",
    "        return True\n",
    "    elif task in {\"workingmemSB\", \"workingmemMB\"} and name == \"workingmem\":\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = {\n",
    "    \"adam\": {\"^apines\", \"apines\", \"Pines^Adam\", \"^apine\"},\n",
    "    \"katherine\": {\"kgrisanz\", \"^kgrisanz\"},\n",
    "    \"monica\": {\"^mkullar\", \"mkullar\", \"^mkullat\"},\n",
    "    \"norween\": {\"^nowreen\", \"nowreen\"},\n",
    "    \"sarah\": {\"sarchang\"},\n",
    "    \"melissa\": {\"mshiner\"},\n",
    "    \"david\": {\"choidd\", \"chiodd\"},\n",
    "    \"bailey\": {\"bholtgos\"},\n",
    "    \"megan\": {\"mchesnut\"},\n",
    "}\n",
    "\n",
    "def _is_operator(operator, name):\n",
    "    names = operators[name]\n",
    "    return operator in names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv(\"/Volumes/hd_4tb/project/clean.csv\")\n",
    "\n",
    "def _get(row, item):\n",
    "    return row[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_df = pd.read_csv(\"/Volumes/hd_4tb/project/slice_timing/all.csv\")\n",
    "\n",
    "def _slice_timing(subject, session, task, check_ascending):\n",
    "    if task.endswith(\"MB\"):\n",
    "        return False\n",
    "    tasknum = {\"gonogo\": 1, \"conscious\": 3, \"workingmemSB\": 4, \"nonconscious\": 5}[task]\n",
    "    selected = slice_df[(\n",
    "        (slice_df.task == tasknum) &\n",
    "        (slice_df.subject.str.lower() == subject) &\n",
    "        (slice_df.session == int(session.replace(\"s\", \"\")))\n",
    "    )]\n",
    "    if len(selected) == 0:\n",
    "        return np.nan\n",
    "    order = selected.order.values[0]\n",
    "    assert order in {\"ascending\", \"descending\"}, \"%s %s %s\" % (subject, session, task)\n",
    "    if check_ascending:\n",
    "        return order == \"ascending\"\n",
    "    else:\n",
    "        return order == \"descending\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _info(row):\n",
    "    ### Setup\n",
    "    info = dict()\n",
    "    subject      = _get(row, \"subject\")\n",
    "    time_session = _get(row, \"time_session\")\n",
    "    task         = _get(row, \"task\")\n",
    "    \n",
    "    ### fMRI\n",
    "    is_mb = task in {\"workingmemMB\"}\n",
    "    info[\"is_mb\"] = is_mb\n",
    "    info[\"is_ascending\"] = _slice_timing(subject, time_session, task, True)\n",
    "    info[\"is_descending\"] = _slice_timing(subject, time_session, task, False)\n",
    "    \n",
    "    ### Task\n",
    "    for task_name in [\"gonogo\", \"conscious\", \"nonconscious\", \"workingmem\"]:\n",
    "        info[\"is_%s\" % task_name] = _is_task(task, task_name)\n",
    "        \n",
    "    ### Operator\n",
    "    misc_operator = True\n",
    "    for operator in operators.keys():\n",
    "        is_operator = _is_operator(_get(row, \"operator\"), operator)\n",
    "        info[\"is_%s\" % operator] = is_operator\n",
    "        if is_operator:\n",
    "            misc_operator = False\n",
    "    info[\"is_misc_operator\"] = misc_operator\n",
    "    \n",
    "    ### Project\n",
    "    for project in [\"connhc\", \"connmdd\", \"engage\", \"rad\"]:\n",
    "        info[\"is_%s\" % project] = _get(row, \"project\") == project\n",
    "        \n",
    "    ### Time session\n",
    "    for session in [\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]:\n",
    "        info[\"is_%s\" % session] = time_session == session\n",
    "        \n",
    "    ### Age, Gender\n",
    "    info[\"age\"] = _get(row, \"age\")\n",
    "    info[\"is_male\"] = _get(row, \"gender\") == \"male\"\n",
    "    info[\"is_female\"] = _get(row, \"gender\") == \"female\"\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2266e5429be14fb0816816b9367fc343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rows = list()\n",
    "for i, row in tqdm(valid.iterrows()):\n",
    "    rows.append(_info(row))\n",
    "    \n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check spread of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 91560.988547\n",
       "is_adam               628.000000\n",
       "is_ascending         1287.000000\n",
       "is_bailey              81.000000\n",
       "is_connhc             175.000000\n",
       "is_connmdd            285.000000\n",
       "is_conscious          660.000000\n",
       "is_david              102.000000\n",
       "is_descending          75.000000\n",
       "is_engage            1002.000000\n",
       "is_female            1425.000000\n",
       "is_gonogo             704.000000\n",
       "is_katherine          435.000000\n",
       "is_male               818.000000\n",
       "is_mb                 100.000000\n",
       "is_megan               53.000000\n",
       "is_melissa            133.000000\n",
       "is_misc_operator      125.000000\n",
       "is_monica             289.000000\n",
       "is_nonconscious       675.000000\n",
       "is_norween            252.000000\n",
       "is_rad                808.000000\n",
       "is_s1                1534.000000\n",
       "is_s2                 220.000000\n",
       "is_s3                 219.000000\n",
       "is_s4                 198.000000\n",
       "is_s5                  99.000000\n",
       "is_sarah              172.000000\n",
       "is_workingmem         231.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check no null inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2270, 29), (2270, 29))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df[df.notnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Volumes/hd_4tb/project/model_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
