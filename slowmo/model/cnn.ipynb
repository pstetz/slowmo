{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from os.path import join, isfile\n",
    "from random import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "root = \"/Users/pstetz/Desktop/confidential/.project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "<div hidden>\n",
    "def _load_model():\n",
    "    lr = LeakyReLU(alpha=0.05); lr.__name__ = 'leaky_relu'\n",
    "    relu = ReLU(); relu.__name__ = \"relu\"\n",
    "    activation = relu\n",
    "    use_bias = False\n",
    "    def layer_a(dim):\n",
    "        return layers.Dense(dim, activation=activation, use_bias=use_bias)\n",
    "    \n",
    "    info_input = keras.Input(shape=(130,), name=\"info\")\n",
    "    prev_input = keras.Input(shape=(9, 9, 9, 2), name=\"prev\")\n",
    "    next_input = keras.Input(shape=(9, 9, 9, 2), name=\"next\")\n",
    "    prev_s, next_s = [prev_input], [next_input]\n",
    "    for i, layer in enumerate([\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.Flatten()\n",
    "    ]):\n",
    "        prev_s.append(layer(prev_s[-1]))\n",
    "        next_s.append(layer(next_s[-1]))\n",
    "    info_s = [info_input]\n",
    "#     for dim in (130, 130, 130):\n",
    "#         info_s.append(layer_a(dim)(info_s[-1]))\n",
    "\n",
    "    x_0 = layers.concatenate([prev_s[-1], next_s[-1], info_s[-1]])\n",
    "    x_s = [x_0]\n",
    "#     for dim in (146, 146, 146, 146, 128, 64, 32):\n",
    "    for dim in (258, 258, 128, 128, 64, 32):\n",
    "        x_s.append(layer_a(dim)(x_s[-1]))\n",
    "    \n",
    "    bold_signal = layers.Dense(1, name=\"bold_signal\")(x_s[-1])\n",
    "    model = keras.Model(inputs=[prev_input, next_input, info_input], outputs=[bold_signal])\n",
    "    learning_rate = 1e-4\n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=8e-2, decay=learning_rate/30),\n",
    "      loss={\"bold_signal\": \"mse\"},\n",
    "      loss_weights=[1.])\n",
    "    return model\n",
    "    \n",
    "def _load_model(with_lgbm = False):\n",
    "    lr = LeakyReLU(alpha=0.05); lr.__name__ = 'leaky_relu'\n",
    "    relu = ReLU(); relu.__name__ = \"relu\"\n",
    "#     activation = lr\n",
    "    \n",
    "    info_input = keras.Input(shape=(130 + int(with_lgbm),), name=\"info\")\n",
    "    prev_input = keras.Input(shape=(9, 9, 9, 2), name=\"prev\")\n",
    "    next_input = keras.Input(shape=(9, 9, 9, 2), name=\"next\")\n",
    "    prev_s, next_s = [prev_input], [next_input]\n",
    "    for i, layer in enumerate([\n",
    "        layers.Conv3D(32, (2, 2, 2), use_bias=False, activation=\"elu\"),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv3D(32, (2, 2, 2), use_bias=False, activation=\"elu\"),\n",
    "        layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        layers.Flatten()\n",
    "    ]):\n",
    "        prev_s.append(layer(prev_s[-1]))\n",
    "        next_s.append(layer(next_s[-1]))\n",
    "    info_s = [info_input]\n",
    "    x_0 = layers.concatenate([prev_s[-1], next_s[-1], info_s[-1]])\n",
    "    x_s = [x_0]\n",
    "    init_shape = x_0.shape[1]\n",
    "    for layer in (\n",
    "        layers.Reshape((init_shape, 1)),\n",
    "        layers.Conv1D(256, 256, strides=init_shape, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((256, 1)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv1D(256, 256, strides=init_shape, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((256, 1)),\n",
    "        layers.Dropout(0.15),\n",
    "        layers.Conv1D(128, 256, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((128, 1)),\n",
    "        layers.Conv1D(64, 128, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((64, 1)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv1D(32, 64, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Reshape((32, 1)),\n",
    "        layers.AveragePooling1D(2),\n",
    "        layers.Flatten(),\n",
    "    ):\n",
    "        x_s.append(layer(x_s[-1]))\n",
    "    \n",
    "    bold_signal = layers.Dense(1, name=\"bold_signal\")(x_s[-1])\n",
    "    model = keras.Model(inputs=[prev_input, next_input, info_input], outputs=[bold_signal])\n",
    "    learning_rate = 1e-3\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=8e-1, decay=learning_rate/30),\n",
    "        loss={\"bold_signal\": \"mse\"}, loss_weights=[1.]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "if \"model\" in locals(): del model\n",
    "model = _load_model()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 258)\n"
     ]
    }
   ],
   "source": [
    "def _load_model():\n",
    "    lr = LeakyReLU(alpha=0.05); lr.__name__ = 'leaky_relu'\n",
    "    relu = ReLU(); relu.__name__ = \"relu\"\n",
    "    activation = lr\n",
    "    use_bias = False\n",
    "    def layer_a(dim):\n",
    "        return layers.Dense(dim, activation=relu, use_bias=use_bias, kernel_constraint=max_norm(3))\n",
    "    \n",
    "    info_input = keras.Input(shape=(130,), name=\"info\")\n",
    "    prev_input = keras.Input(shape=(9, 9, 9, 2), name=\"prev\")\n",
    "    next_input = keras.Input(shape=(9, 9, 9, 2), name=\"next\")\n",
    "    prev_s, next_s = [prev_input], [next_input]\n",
    "    for i, layer in enumerate([\n",
    "        layers.Conv3D(4, (2, 2, 2), use_bias=False, kernel_constraint=max_norm(3)),\n",
    "        layers.Conv3D(4, (2, 2, 2), use_bias=False, kernel_constraint=max_norm(3)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"elu\", kernel_constraint=max_norm(3)),\n",
    "    ]):\n",
    "        prev_s.append(layer(prev_s[-1]))\n",
    "        next_s.append(layer(next_s[-1]))\n",
    "    info_s = [info_input]\n",
    "    x_0 = layers.concatenate([prev_s[-1], next_s[-1], info_s[-1]])\n",
    "    print(x_0.shape)\n",
    "    x_s = [x_0]\n",
    "    for dim in (258, 256, 256, 128, 128): #, 128, 128, 128, 64, 32):\n",
    "        x_s.append(layer_a(dim)(x_s[-1]))\n",
    "#         x_s.append(layers.BatchNormalization()(x_s[-1]))\n",
    "#         x_s.append(layers.Dropout(0.5)(x_s[-1]))\n",
    "    \n",
    "    bold_signal = layers.Dense(1, name=\"bold_signal\")(x_s[-1])\n",
    "    model = keras.Model(inputs=[prev_input, next_input, info_input], outputs=[bold_signal])\n",
    "    learning_rate = 5e-4\n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=3e-2, decay=learning_rate/20),\n",
    "      loss={\"bold_signal\": \"mse\"},\n",
    "      loss_weights=[1.])\n",
    "    return model\n",
    "\n",
    "if \"model\" in locals(): del model\n",
    "model = _load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"/Users/pstetz/Desktop/confidential/.project/summary/consolidate\"\n",
    "log_dir = join(root, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "history = History()\n",
    "\n",
    "batch_size = 32\n",
    "num_epoches = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histories = list()\n",
    "for _ in range(4):\n",
    "    for batch_path in tqdm(glob(join(training_path, \"*\"))):\n",
    "        batch = pickle.load(open(batch_path, \"rb\"))\n",
    "        bold_signal = batch.pop(\"pred\")\n",
    "        model.fit(\n",
    "            batch, bold_signal,\n",
    "            epochs=num_epoches, batch_size=batch_size, verbose=True,\n",
    "            callbacks=[tensorboard_callback, history],\n",
    "            validation_split=0.2,\n",
    "            shuffle=True # use when randomly selecting batches\n",
    "        )\n",
    "        histories.append(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {\"loss\": [], \"val_loss\": []}\n",
    "for h in histories:\n",
    "    tmp[\"loss\"].extend(h[\"loss\"])\n",
    "    tmp[\"val_loss\"].extend(h[\"val_loss\"])\n",
    "    \n",
    "pd.DataFrame(tmp).to_csv(\"/Users/pstetz/Desktop/confidential/.project/4_65_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Users/pstetz/Desktop/confidential/.project/run/4_65_score.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
