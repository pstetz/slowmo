{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from os.path import join, isfile\n",
    "from random import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "tf.random.set_seed(5)\n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "root = \"/Users/pstetz/Desktop/confidential/.project\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(history_path, data):\n",
    "    if isfile(history_path):\n",
    "        pd.concat([pd.read_csv(history_path), pd.DataFrame(data)]).to_csv(history_path, index=False)\n",
    "    else:\n",
    "        pd.DataFrame(data).to_csv(history_path, index=False)\n",
    "        \n",
    "with open(\"/Users/pstetz/Desktop/confidential/.project/summary/info_order.json\", \"r\") as f:\n",
    "    renaming = json.load(f)\n",
    "renaming = {int(k): v for k, v in renaming.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "<div hidden>\n",
    "def _load_model():\n",
    "    lr = LeakyReLU(alpha=0.05); lr.__name__ = 'leaky_relu'\n",
    "    relu = ReLU(); relu.__name__ = \"relu\"\n",
    "    activation = relu\n",
    "    use_bias = False\n",
    "    def layer_a(dim):\n",
    "        return layers.Dense(dim, activation=activation, use_bias=use_bias)\n",
    "    \n",
    "    info_input = keras.Input(shape=(130,), name=\"info\")\n",
    "    prev_input = keras.Input(shape=(9, 9, 9, 2), name=\"prev\")\n",
    "    next_input = keras.Input(shape=(9, 9, 9, 2), name=\"next\")\n",
    "    prev_s, next_s = [prev_input], [next_input]\n",
    "    for i, layer in enumerate([\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.MaxPool3D(),\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.Flatten()\n",
    "    ]):\n",
    "        prev_s.append(layer(prev_s[-1]))\n",
    "        next_s.append(layer(next_s[-1]))\n",
    "    info_s = [info_input]\n",
    "#     for dim in (130, 130, 130):\n",
    "#         info_s.append(layer_a(dim)(info_s[-1]))\n",
    "\n",
    "    x_0 = layers.concatenate([prev_s[-1], next_s[-1], info_s[-1]])\n",
    "    x_s = [x_0]\n",
    "#     for dim in (146, 146, 146, 146, 128, 64, 32):\n",
    "    for dim in (258, 258, 128, 128, 64, 32):\n",
    "        x_s.append(layer_a(dim)(x_s[-1]))\n",
    "    \n",
    "    bold_signal = layers.Dense(1, name=\"bold_signal\")(x_s[-1])\n",
    "    model = keras.Model(inputs=[prev_input, next_input, info_input], outputs=[bold_signal])\n",
    "    learning_rate = 1e-4\n",
    "    model.compile(optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=8e-2, decay=learning_rate/30),\n",
    "      loss={\"bold_signal\": \"mse\"},\n",
    "      loss_weights=[1.])\n",
    "    return model\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model(with_lgbm = False):\n",
    "    lr = LeakyReLU(alpha=0.05); lr.__name__ = 'leaky_relu'\n",
    "    relu = ReLU(); relu.__name__ = \"relu\"\n",
    "#     activation = lr\n",
    "    \n",
    "    info_input = keras.Input(shape=(130 + int(with_lgbm),), name=\"info\")\n",
    "    prev_input = keras.Input(shape=(9, 9, 9, 2), name=\"prev\")\n",
    "    next_input = keras.Input(shape=(9, 9, 9, 2), name=\"next\")\n",
    "    prev_s, next_s = [prev_input], [next_input]\n",
    "    for i, layer in enumerate([\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.Conv3D(8, (2, 2, 2), use_bias=False),\n",
    "        layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        layers.Flatten()\n",
    "    ]):\n",
    "        prev_s.append(layer(prev_s[-1]))\n",
    "        next_s.append(layer(next_s[-1]))\n",
    "    info_s = [info_input]\n",
    "    x_0 = layers.concatenate([prev_s[-1], next_s[-1], info_s[-1]])\n",
    "    x_s = [x_0]\n",
    "    init_shape = x_0.shape[1]\n",
    "    for layer in (\n",
    "        layers.Reshape((init_shape, 1)),\n",
    "        layers.Conv1D(256, 256, strides=init_shape, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((256, 1)),\n",
    "        layers.Conv1D(256, 256, strides=init_shape, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((256, 1)),\n",
    "        layers.Conv1D(128, 256, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((128, 1)),\n",
    "        layers.Conv1D(64, 128, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((64, 1)),\n",
    "        layers.Conv1D(32, 64, activation='elu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Reshape((32, 1)),\n",
    "        layers.AveragePooling1D(2),\n",
    "        layers.Flatten(),\n",
    "    ):\n",
    "        x_s.append(layer(x_s[-1]))\n",
    "    \n",
    "    bold_signal = layers.Dense(1, name=\"bold_signal\")(x_s[-1])\n",
    "    model = keras.Model(inputs=[prev_input, next_input, info_input], outputs=[bold_signal])\n",
    "    learning_rate = 1e-3\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=8e-1, decay=learning_rate/30),\n",
    "        loss={\"bold_signal\": \"mse\"}, loss_weights=[1.]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "if \"model\" in locals(): del model\n",
    "model = _load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_path = join(root, \"dual_history.csv\")\n",
    "training_path = join(root, \"training\")\n",
    "log_dir = join(root, \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "train_batch  = 128\n",
    "input_batch  = train_batch * 2\n",
    "num_epoches = 2\n",
    "\n",
    "if isfile(history_path):\n",
    "    os.remove(history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try double model (lgbm + CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lgbm_input(batch, renaming):\n",
    "    df = pd.DataFrame(batch[\"info\"])\n",
    "    df.rename(columns=renaming, inplace=True)\n",
    "    df[\"prev\"] = batch[\"prev\"][:, 4, 4, 4, 0]\n",
    "    df[\"next\"] = batch[\"next\"][:, 4, 4, 4, 0]\n",
    "    df[\"grey\"] = batch[\"next\"][:, 4, 4, 4, 1]\n",
    "    return df\n",
    "\n",
    "lgbm_path = \"/Users/pstetz/Desktop/confidential/.project/run/lgbm/2_norm.pkl\"\n",
    "\n",
    "with open(lgbm_path, \"rb\") as f:\n",
    "    lgbm_model = pickle.load(f)\n",
    "    \n",
    "model = _load_model(with_lgbm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pstetz/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2347ab34c2ed4c39a655d96f744aa640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24513.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 23s 704us/sample - loss: 0.7963\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 20s 617us/sample - loss: 0.7434\n",
      "0.743 0.7524904012680054\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 19s 567us/sample - loss: 0.7289\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 19s 586us/sample - loss: 0.7197\n",
      "0.72 0.7295564413070679\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 18s 557us/sample - loss: 0.7353\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 16s 499us/sample - loss: 0.7270\n",
      "0.727 0.7439282536506653\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 20s 599us/sample - loss: 0.7196\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 17s 531us/sample - loss: 0.7150\n",
      "0.715 0.7309716939926147\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 15s 462us/sample - loss: 0.7092\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 16s 493us/sample - loss: 0.7038\n",
      "0.704 0.7257223725318909\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 16s 486us/sample - loss: 0.7249\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 16s 495us/sample - loss: 0.7196\n",
      "0.72 0.7451053857803345\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 14s 426us/sample - loss: 0.6925\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 19s 581us/sample - loss: 0.6883\n",
      "0.688 0.7117005586624146\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 20s 604us/sample - loss: 0.6981\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 20s 597us/sample - loss: 0.6947\n",
      "0.695 0.706067681312561\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 16s 499us/sample - loss: 0.6962\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 24s 727us/sample - loss: 0.6918\n",
      "0.692 0.7278833985328674\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 37s 1ms/sample - loss: 0.7003\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 40s 1ms/sample - loss: 0.6971\n",
      "0.697 0.7190454602241516\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 22s 662us/sample - loss: 0.7142\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 22s 674us/sample - loss: 0.7107\n",
      "0.711 0.7458046674728394\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 21s 654us/sample - loss: 0.6849\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 23s 703us/sample - loss: 0.6816\n",
      "0.682 0.7042561769485474\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 18s 546us/sample - loss: 0.6862\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 21s 643us/sample - loss: 0.6820\n",
      "0.682 0.7117928862571716\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 20s 600us/sample - loss: 0.7057\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 20s 604us/sample - loss: 0.7026\n",
      "0.703 0.7409476041793823\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 21s 641us/sample - loss: 0.7051\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 30s 928us/sample - loss: 0.7019\n",
      "0.702 0.7481905221939087\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 43s 1ms/sample - loss: 0.6966\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 18s 545us/sample - loss: 0.6948\n",
      "0.695 0.7306973338127136\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 15s 453us/sample - loss: 0.7003\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 13s 407us/sample - loss: 0.6972\n",
      "0.697 0.735634982585907\n",
      "Train on 32768 samples\n",
      "Epoch 1/2\n",
      "32768/32768 [==============================] - 13s 412us/sample - loss: 0.7035\n",
      "Epoch 2/2\n",
      "32768/32768 [==============================] - 14s 417us/sample - loss: 0.7010\n",
      "0.701 0.7217112183570862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures)\u001b[0m\n\u001b[1;32m   3063\u001b[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[1;32m   3064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The \"%s\" trait is read-only.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mold_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trait_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cross_validation_lock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_cross_validate\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trait_validators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0mproposal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'trait'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'owner'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trait_validators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bold_signal, prev_volume, next_volume, info = [], [], [], []\n",
    "for _ in range(4):\n",
    "    training = glob(join(training_path, \"*\", \"*\"))\n",
    "    shuffle(training)\n",
    "    for i, batch_path in enumerate(tqdm(training)):\n",
    "        if not isfile(join(batch_path, \"norm_info.npy\")):\n",
    "            print(\"%s not found\" % batch_path)\n",
    "            continue\n",
    "        bold_signal.extend(np.load(join(batch_path, \"pred.npy\")))\n",
    "        prev_volume.extend(np.load(join(batch_path, \"norm_prev.npy\")))\n",
    "        next_volume.extend(np.load(join(batch_path, \"norm_next.npy\")))\n",
    "        info.extend(np.load(join(batch_path, \"norm_info.npy\"), allow_pickle=True))\n",
    "        if (i + 1) % input_batch == 0:\n",
    "            batch = {\n",
    "                \"prev\": np.array(prev_volume),\n",
    "                \"next\": np.array(next_volume),\n",
    "                \"info\": np.array(info, dtype=np.float32)\n",
    "            }\n",
    "            lgbm_input = create_lgbm_input(batch, renaming)\n",
    "            lgbm_preds = lgbm_model.predict(lgbm_input).reshape(len(batch[\"info\"]), 1)\n",
    "            batch[\"info\"] = np.hstack((batch[\"info\"], lgbm_preds))\n",
    "            bold_signal = np.array(bold_signal)\n",
    "            history = model.fit(\n",
    "                batch, bold_signal,\n",
    "                epochs=num_epoches, batch_size=train_batch, verbose=True,\n",
    "                callbacks=[tensorboard_callback],\n",
    "                shuffle=True # use when randomly selecting batches\n",
    "            )\n",
    "            _std = np.std(bold_signal).round(3)\n",
    "            _loss = history.history[\"loss\"][-1].round(3)\n",
    "            assert not np.isnan(_loss), batch_path\n",
    "            _mean = np.add(batch[\"prev\"][:, 4, 4, 4, 0], batch[\"next\"][:, 4, 4, 4, 0]) / 2\n",
    "            mean_loss = np.sum(np.square(np.subtract(_mean, bold_signal))) / len(bold_signal)\n",
    "            print(_loss, mean_loss)\n",
    "            data = {\n",
    "                \"std\": [_std] * num_epoches,\n",
    "                \"loss\": history.history[\"loss\"],\n",
    "                \"mean_loss\": mean_loss\n",
    "            }\n",
    "            save_history(history_path, data)\n",
    "            bold_signal, prev_volume, next_volume, info = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
