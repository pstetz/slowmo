{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grey masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_001716': 1, 'in_013136': 0, 'in_073720': 0, 'in_125909': 0, 'in_131520': 0, 'in_156999': 0, 'in_176064': 0, 'in_182355': 0, 'in_216192': 0, 'in_275836': 0, 'in_291082': 0, 'in_414207': 0, 'in_426426': 0, 'in_447647': 0, 'in_450767': 0, 'in_477522': 0, 'in_525931': 0, 'in_532911': 0, 'in_533294': 0, 'in_534482': 0, 'in_707656': 0, 'in_752691': 0, 'in_779062': 0, 'in_791103': 0, 'in_831650': 0, 'in_877949': 0, 'in_911981': 0, 'in_954861': 0}\n"
     ]
    }
   ],
   "source": [
    "masks = glob(\"/Volumes/hd_4tb/masks/plip/*\")\n",
    "masks = [{\n",
    "    \"code\": os.path.basename(mask).split(\"_\")[0],\n",
    "    \"data\": nib.load(mask).get_data(),\n",
    "} for mask in masks]\n",
    "\n",
    "def _in_mask(masks, x, y, z):\n",
    "    result = dict()\n",
    "    for mask in masks:\n",
    "        code = mask[\"code\"]\n",
    "        data = mask[\"data\"]\n",
    "        result[\"in_%s\" % code] = int(bool(data[x, y, z]))\n",
    "    return result\n",
    "\n",
    "def _mean_activation(masks, fmri, grey, t, label):\n",
    "    activations = dict()\n",
    "    for mask in masks:\n",
    "        code, data = mask[\"code\"], mask[\"data\"]\n",
    "        region = np.multiply(data, fmri[:, :, :, t])\n",
    "        activations[\"mean_%s_%s\" % (code, label)] = np.mean( np.multiply(grey, region) )\n",
    "    return activations\n",
    "\n",
    "def _mask_info(masks, fmri, grey, coord):\n",
    "    x, y, z, t = coord\n",
    "    info = _in_mask(masks, x, y, z)\n",
    "    for timepoint, label in [(t-1, \"prev\"), (t+1, \"next\")]:\n",
    "        info = {**info, **_mean_activation(masks, fmri, grey, timepoint, label)}\n",
    "    info[\"x\"] = x\n",
    "    info[\"y\"] = y\n",
    "    info[\"z\"] = z\n",
    "    info[\"t\"] = t\n",
    "    return info\n",
    "\n",
    "print(_in_mask(masks, 49, 66, 33))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_volume(fmri, x, y, z, t):\n",
    "    volume = nii_input(fmri[:, :, :, t], x, y, z)\n",
    "    return np.array(volume)\n",
    "\n",
    "def _load(filepath):\n",
    "    return nib.as_closest_canonical(nib.load(filepath))\n",
    "\n",
    "def _get_data(filepath):\n",
    "    image = _load(filepath)\n",
    "    return image.get_data()\n",
    "\n",
    "def _time_map(session):\n",
    "    _map = {\n",
    "        \"s1\": \"000\", \"s2\": \"2MO\", \"s3\": \"6MO\", \"s4\": \"12MO\", \"s5\": \"24MO\"\n",
    "    }\n",
    "    return _map[session]\n",
    "\n",
    "def _get(row, item):\n",
    "    return row[item]\n",
    "\n",
    "def _fmri_path(row):\n",
    "    _input = \"/Volumes/hd_4tb/raw\"\n",
    "    project = _get(row, \"project\")\n",
    "    subject = _get(row, \"subject\")\n",
    "    time_session = _get(row, \"time_session\")\n",
    "    task = _get(row, \"task\")\n",
    "    return join(_input, project, _time_map(time_session), subject, task)\n",
    "\n",
    "def nii_input(data, x, y, z, r = 4):\n",
    "    return data[\n",
    "        x - r : x + r + 1,\n",
    "        y - r : y + r + 1,\n",
    "        z - r : z + r + 1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onset_time(onsets, curr_time):\n",
    "    onset = onsets[onsets[\"ons\"] < curr_time]\n",
    "    onset = onset.sort_values(\"ons\", ascending=False)\n",
    "    if len(onset) > 0:\n",
    "        _time = onset.iloc[0].ons\n",
    "        return curr_time - _time\n",
    "    return False\n",
    "\n",
    "def _stim_time(df, stimuli, curr_time):\n",
    "    stim = df[df.category == stimuli]\n",
    "    return _onset_time(stim, curr_time)\n",
    "\n",
    "def _keypress_times(df, button, curr_time):\n",
    "    keys = df[(\n",
    "        (df[\"category\"] == \"keypress\") &\n",
    "        (df[\"stimulus\"] == button)\n",
    "    )]\n",
    "    return _onset_time(keys, curr_time)\n",
    "\n",
    "def last_onset(onset_df, task, curr_time, max_time=1000):\n",
    "    task_stimuli = {\n",
    "        \"gonogo\":       [\"Go\", \"NoGo\"],\n",
    "        \"conscious\":    [\"Anger\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\"],\n",
    "        \"nonconscious\": [\"Anger\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\"],\n",
    "        \"workingmemSB\": [\"Baseline\", \"NonTarget\", \"Target\"],\n",
    "        \"workingmemMB\": [\"Baseline\", \"NonTarget\", \"Target\"],\n",
    "    }\n",
    "    all_stimuli  = set(np.concatenate(list(task_stimuli.values())))\n",
    "    onset_timing = {stimuli: max_time for stimuli in all_stimuli}\n",
    "    for button in [\"1\", \"6\"]:\n",
    "        onset_timing[button] = _keypress_times(onset_df, button, curr_time)\n",
    "        \n",
    "    for stimuli in task_stimuli[task]:\n",
    "        _time = _stim_time(onset_df, stimuli, curr_time)\n",
    "        if _time:\n",
    "            onset_timing[stimuli] = _time\n",
    "    return pd.DataFrame(onset_timing, index=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = _load_model()\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df                = pd.read_csv(\"/Volumes/hd_4tb/project/model_input.csv\")\n",
    "available_volumes = np.load(\"available_volumes.npy\")\n",
    "train_cols        = [c for c in df.columns if c.startswith(\"is_\")] + [\"age\"]\n",
    "\n",
    "training_path = \"/Volumes/hd_4tb/results/training\"\n",
    "batch_size  = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "For working with multiple inputs/outputs see [here](https://www.tensorflow.org/guide/keras/functional#models_with_multiple_inputs_and_outputs).  NN advice [here](https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn?noredirect=1&lq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connmdd conn209 s1 gonogo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2fe25ec5d848a98f135944df385d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connmdd conn209 s1 nonconscious\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68260d33030646d892bec669af30355e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connmdd conn209 s1 workingmemMB\n",
      "connmdd conn211 s1 conscious\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6615dae33770432e92106a154964e910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connmdd conn211 s1 gonogo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bfc656cd2e44c0bd6d35f17bc394d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connmdd conn211 s1 nonconscious\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a1d900cf334764a87cadc4d1a3508d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connmdd conn211 s1 workingmemMB\n",
      "engage la13012 s1 conscious\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bf68664cb143e2a4e1e2d62c112583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engage la13012 s1 gonogo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e88e7c198f47ae8907b7f72bbf8f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engage la13012 s1 nonconscious\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ad20239b0f4d70b59ce16da82fab5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1280), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engage la13272 s1 conscious\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c87a73c5450a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"prev\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"next\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbold_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtraining_voxels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcartesian\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mavailable_volumes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtraining_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_voxels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c87a73c5450a>\u001b[0m in \u001b[0;36mcartesian\u001b[0;34m(data, timepoints)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtimepoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def cartesian(data, timepoints):\n",
    "    ret = list()\n",
    "    for x, y, z in data:\n",
    "        for t in timepoints:\n",
    "            ret.append((x, y, z, t))\n",
    "    return ret\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if i < 453:\n",
    "        continue\n",
    "    print(_get(row, \"project\"), _get(row, \"subject\"), _get(row, \"time_session\"), _get(row, \"task\"))\n",
    "    TR = 2 if _get(row, \"is_mb\") == 0 else 0.71\n",
    "    task = _get(row, \"task\")\n",
    "    if task == \"workingmemMB\":\n",
    "        continue\n",
    "\n",
    "    fmri_path = _fmri_path(row)\n",
    "    fmri      = _get_data(join(fmri_path, \"normalized.nii.gz\"))\n",
    "    grey      = _get_data(join(fmri_path, \"..\", \"structural\", \"gm_probseg.nii.gz\"))\n",
    "    onset_df  = pd.read_csv(join(fmri_path, \"onsets.csv\"))\n",
    "    info = pd.concat([pd.DataFrame(row[train_cols]).T] * batch_size).reset_index(drop=True)\n",
    "    \n",
    "    batch = {\"prev\": list(), \"next\": list()}\n",
    "    bold_signal, mask_rows = list(), list()\n",
    "    training_voxels = cartesian( available_volumes, np.array(range(1, fmri.shape[3]-1)) )\n",
    "    training_index = random.sample(range(len(training_voxels)), batch_size*10)\n",
    "\n",
    "    for j, index in tqdm(enumerate(training_index), total=batch_size*10):\n",
    "        x, y, z, t = training_voxels[index]\n",
    "        onsets = last_onset(onset_df, task, TR * t, max_time=1000)\n",
    "        onsets = pd.concat([onsets] * batch_size).reset_index(drop=True)\n",
    "        \n",
    "        mask_rows.append( _mask_info(masks, fmri, grey, (x, y, z, t))  )\n",
    "        grey_data = nii_input(grey, x, y, z)\n",
    "        for name, timepoint in [(\"prev\", t-1), (\"next\", t+1)]:\n",
    "            batch[name].append(\n",
    "                np.stack((_load_volume(fmri, x, y, z, timepoint), grey_data), axis=3)\n",
    "            )\n",
    "        bold_signal.append(fmri[x, y, z, t])\n",
    "        \n",
    "        ### Fit to data\n",
    "        if (j + 1) % batch_size == 0:\n",
    "            input_folder = join(training_path, \"%04d/%02d\" % (i, j // batch_size))\n",
    "            if not os.path.isdir(input_folder):\n",
    "                os.makedirs(input_folder)\n",
    "            batch[\"info\"] = pd.concat([\n",
    "                onsets, info, pd.DataFrame(mask_rows)\n",
    "            ], axis=1)\n",
    "            batch[\"prev\"], batch[\"next\"] = np.array(batch[\"prev\"]), np.array(batch[\"next\"])\n",
    "            preds = np.array(bold_signal)\n",
    "            np.save(join(input_folder, \"prev.npy\"), batch[\"prev\"])\n",
    "            np.save(join(input_folder, \"next.npy\"), batch[\"next\"])\n",
    "            np.save(join(input_folder, \"info.npy\"), batch[\"info\"])\n",
    "            np.save(join(input_folder, \"pred.npy\"), preds)\n",
    "            batch = {\"prev\": list(), \"next\": list()}\n",
    "            bold_signal, mask_rows = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
