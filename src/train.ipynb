{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from random import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pbezuhov/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "def _load_model():\n",
    "    info_input = keras.Input(shape=(130,), name=\"info\")\n",
    "    prev_input = keras.Input(shape=(9, 9, 9, 2), name=\"prev\")\n",
    "    next_input = keras.Input(shape=(9, 9, 9, 2), name=\"next\")\n",
    "\n",
    "    prev_s, next_s = [prev_input], [next_input]\n",
    "    for layer in [\n",
    "        layers.Conv3D(2, (3, 3, 3), use_bias=False),\n",
    "        layers.Conv3D(2, (2, 2, 2), use_bias=False),\n",
    "        layers.Flatten()\n",
    "    ]:\n",
    "        prev_s.append(layer(prev_s[-1]))\n",
    "        next_s.append(layer(next_s[-1]))\n",
    "    \n",
    "    info_s = [info_input]\n",
    "    for layer in [\n",
    "        layers.Dense(130, activation=LeakyReLU(alpha=0.05)),\n",
    "        layers.Dense(130, activation=LeakyReLU(alpha=0.05)),\n",
    "#         layers.Dense(130),\n",
    "#         layers.Dense(130)\n",
    "    ]:\n",
    "        info_s.append(layer(info_s[-1]))\n",
    "\n",
    "    x_0 = layers.concatenate([prev_s[-1], next_s[-1], info_s[-1]])\n",
    "#     x_0 = layers.concatenate([prev_s[-1], next_s[-1]])\n",
    "    x_s = [x_0]\n",
    "    for layer in [\n",
    "#         layers.Dense(994, activation=LeakyReLU(alpha=0.05)),\n",
    "        layers.Dense(994, activation=\"relu\"),\n",
    "#         layers.Dropout(0.25),\n",
    "        layers.Dense(800, activation=\"relu\"),\n",
    "#         layers.Dense(800),\n",
    "#         layers.Dropout(0.25),\n",
    "#         layers.Dense(512, activation=\"sigmoid\"),\n",
    "#         layers.Dense(256, activation=\"sigmoid\"),\n",
    "#         layers.Dense(256, activation=\"sigmoid\"),\n",
    "#         layers.Dense(128, activation=LeakyReLU(alpha=0.05)),\n",
    "#         layers.Dense( 64, activation=LeakyReLU(alpha=0.05)),\n",
    "        layers.Dense( 32, activation=\"relu\"),\n",
    "    ]:\n",
    "        x_s.append(layer(x_s[-1]))\n",
    "    \n",
    "    bold_signal = layers.Dense(1, activation=\"sigmoid\", name=\"bold_signal\")(x_s[-1])\n",
    "\n",
    "    model = keras.Model(inputs=[prev_input, next_input, info_input], outputs=[bold_signal])\n",
    "#     model = keras.Model(inputs=[prev_input, next_input], outputs=[bold_signal])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "      loss={\"bold_signal\": \"mse\"},\n",
    "      loss_weights=[1.])\n",
    "    return model\n",
    "\n",
    "log_dir=\"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model = _load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_path = \"/Volumes/hd_4tb/results/history.csv\"\n",
    "checkpoint_path = \"/Volumes/hd_4tb/results/checkpoints\"\n",
    "training_path = \"/Volumes/hd_4tb/results/training\"\n",
    "batch_size  = 128\n",
    "num_epoches = 3\n",
    "\n",
    "if os.path.isfile(history_path):\n",
    "    os.remove(history_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5508730f6b0c4f8c9ba3029ffd460fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13357), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training = glob(join(training_path, \"*\", \"*\"))\n",
    "# shuffle(training)\n",
    "\n",
    "bold_signal, prev_volume, next_volume, info = [], [], [], []\n",
    "for i, batch_path in enumerate(tqdm(training)):\n",
    "    bold_signal.extend(np.load(join(batch_path, \"pred.npy\")))\n",
    "    prev_volume.extend(np.load(join(batch_path, \"prev.npy\")))\n",
    "    next_volume.extend(np.load(join(batch_path, \"next.npy\")))\n",
    "    info.extend(np.load(join(batch_path, \"norm_info.npy\"), allow_pickle=True))\n",
    "    if (i + 1) % 10 == 0:        \n",
    "        batch = {\n",
    "            \"prev\": np.array(prev_volume),\n",
    "            \"next\": np.array(next_volume),\n",
    "            \"info\": np.array(info, dtype=np.float32)\n",
    "        }\n",
    "        bold_signal = np.array(bold_signal)\n",
    "        assert not np.sum(np.isnan(bold_signal))\n",
    "        for _k in batch:\n",
    "            assert not np.sum(np.isnan(batch[_k]))\n",
    "        history = model.fit(\n",
    "            batch, {'bold_signal': bold_signal},\n",
    "            epochs=num_epoches, batch_size=batch_size, verbose=False,\n",
    "            callbacks=[tensorboard_callback],\n",
    "            shuffle=True # use when randomly selecting batches\n",
    "        )\n",
    "        preds = model.predict(batch, batch_size=batch_size)\n",
    "#         print(len(set([p[0] for p in preds])), set([p[0] for p in preds]))\n",
    "#         print()\n",
    "        _std = np.std(bold_signal).round(3)\n",
    "        _loss = history.history[\"loss\"][0].round(3)\n",
    "#         print(_loss)\n",
    "        assert not np.isnan(_loss), batch_path\n",
    "        prev_weights = model.get_weights()\n",
    "        data = {\"std\": [_std] * num_epoches, \"loss\": history.history[\"loss\"]}\n",
    "        if os.path.isfile(history_path):\n",
    "            pd.concat([pd.read_csv(history_path), pd.DataFrame(data)]).to_csv(history_path, index=False)\n",
    "        else:\n",
    "            pd.DataFrame(data).to_csv(history_path, index=False)\n",
    "        bold_signal, prev_volume, next_volume, info = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Volumes/hd_4tb/results/just_voxels.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
