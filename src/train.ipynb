{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "# Table of Contents\n",
    "\n",
    "1.) [Intro](#intro)  \n",
    "2.) [Imports](#imports)  \n",
    "3.) [Setup](#setup)  \n",
    "4.) [Helpers](#helpers)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "### [^](#toc) Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original SlowMo [paper presented here](https://people.cs.umass.edu/~hzjiang//projects/superslomo/) [and here](https://arxiv.org/abs/1712.00080), the team trained on 1,132 Youtube videos or 300K individual frames.\n",
    "\n",
    "While this sounds like a lot we have just as much.  CONNECTOME, ENGAGE, and RAD have a combined ~1,500 sessions on Flywheel and a estimate of 3 tasks per session and 150 volumes per task mean we have 675,000 individual frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of features:', 625)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_num = 20\n",
    "\n",
    "\"Number of features:\", (\n",
    "    (247 * 2) + # 4 radius voxels (previous and next) (not directly adjacent)\n",
    "    (2 * mask_num * 2) + # (loop over masks) mean/std of mask (next and previous)\n",
    "    2 + # time since (until) previous (next)\n",
    "    1 + # time ratio between next voxels and previous\n",
    "    2 + # time since last gonogo stimuli\n",
    "    2 + # time since go/nogo bloack started\n",
    "    6 + # time since faces stimuli\n",
    "    6 + # time since faces block started\n",
    "    1 + # time since keypress (any)\n",
    "    3 + # gender, age, scl20\n",
    "    4 + # task identifier (is_gonogo, is_(non)conscious, is_wm)\n",
    "    3 + # study identifier (conn, engage, rad)\n",
    "    mask_num + # flags if voxel within mask\n",
    "    1 + # is_grey_matter\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "### [^](#toc) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "### [^](#toc) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masks_path = \"/Volumes/group/pstetz/git/PANLab/PANLab_fMRI_scripts/config/PanLab_Masks_Biotypes_May2019.csv\"\n",
    "masks_dir  = \"/Volumes/group/PANLab_Datasets/Masks/Parcels/Neurosynth_maps/Nature_Medicine_RR/ROI_masks_for_revision\"\n",
    "\n",
    "with open(masks_path) as f:\n",
    "    mask_names = f.readlines()\n",
    "    mask_names = [m[:-1] for m in mask_names] # remove \\n character\n",
    "    \n",
    "masks = [os.path.join(masks_dir, m + \".nii\") for m in mask_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"helpers\"></a>\n",
    "### [^](#toc) Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filepath):\n",
    "    assert os.path.isfile(filepath), \"%s does not exist\"\n",
    "    image = nib.load(fn)\n",
    "    return nib.as_closest_canonical(image)\n",
    "\n",
    "def mask_image(image, mask):\n",
    "    if len(image.shape) == 3:\n",
    "        return np.multiply(image, mask)\n",
    "    assert len(image.shape) == 4, \"%s is not a valid image shape.\" % str(image.shape)\n",
    "    \n",
    "    masked_imaged = image.copy()\n",
    "    for i in range(image.shape[3]):\n",
    "        masked_image[i] = np.multiply(image[i], mask)\n",
    "    return masked_image\n",
    "\n",
    "def mask_mean_std(image, mask):\n",
    "    \"\"\" FIXME: might want to norm each voxel before taking the mean/std \"\"\"\n",
    "    masked_image = mask_image(image, mask)\n",
    "    return mask_image.mean(), mask_image.std()\n",
    "\n",
    "def norm_voxel(data, x, y, z, t):\n",
    "    assert len(data.shape) == 4, \"The dimension size should be 4 not %s\" % str(data.shape)\n",
    "    voxel = data[x, y, z, :]\n",
    "    return (voxel[t] - voxel.mean()) / voxel.std()\n",
    "\n",
    "def trainable_mask(mask, radius):\n",
    "    \"\"\" Given a mask determine what voxels are [radius] away from the outside \"\"\"\n",
    "    trainable_mask = mask.copy()\n",
    "    x_size, y_size, z_size = mask.shape\n",
    "    for x in range(x_size):\n",
    "        for y in range(y_size):\n",
    "            for z in range(z_size):\n",
    "                if mask[x, y, z] == 0:\n",
    "                    continue\n",
    "                if not within_radius(mask, x, y, z, radius):\n",
    "                    trainable_mask[x, y, z] = 0\n",
    "    return trainable_mask\n",
    "\n",
    "def voxel_radius(radius):\n",
    "    valid = list()\n",
    "    count = 0\n",
    "\n",
    "    for i in range(radius+1):\n",
    "        for j in range(radius+1):\n",
    "            for k in range(radius+1):\n",
    "                if i == 0 and j == 0 and k == 0:\n",
    "                    continue\n",
    "                if i**2 + j**2 + k**2 > radius**2:\n",
    "                    continue\n",
    "\n",
    "                for parity in ([1, 1, 1], [-1, 1, 1], [1, -1, 1], [1, 1, -1],\n",
    "                               [-1, -1, 1], [-1, 1, -1], [1, -1, -1], [-1, -1, -1]):\n",
    "                    if ((i == 0 and parity[0] == -1) or\n",
    "                        (j == 0 and parity[1] == -1) or\n",
    "                        (k == 0 and parity[2] == -1)):\n",
    "                        continue\n",
    "                    valid.append({\"x\":  i * parity[0], \"y\":  j * parity[1], \"z\":  k * parity[2]})\n",
    "    print(len(valid), (2 * radius + 1)**3)\n",
    "    return valid\n",
    "#     return count, (2 * radius + 1)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 729\n"
     ]
    }
   ],
   "source": [
    "voxel_radius(4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
