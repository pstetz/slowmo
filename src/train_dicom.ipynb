{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import flywheel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "### Custom helpers\n",
    "import sys\n",
    "sys.path.append(\"classes\")\n",
    "from helpers import *\n",
    "from Model import Model\n",
    "from Cloud import Cloud\n",
    "from Button import Button\n",
    "from Dicom import Dicom, DicomDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Number of features:', 776)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = (\n",
    "    (len(voxel_radius(4)) * 2) + # 4 radius voxels (previous and next volume)\n",
    "    (len(voxel_radius(4)) - len(voxel_radius(2))) + # 4 radius voxels not within 2 voxel radius for current volume\n",
    "    2 + # time since (until) previous (next)\n",
    "    1 + # time ratio between next voxels and previous\n",
    "    2 + # time since last gonogo stimuli\n",
    "    2 + # time since go/nogo bloack started\n",
    "    6 + # time since faces stimuli\n",
    "    6 + # time since faces block started\n",
    "    2 + # time since wm stimuli\n",
    "    2 + # time since wm block started\n",
    "    2 + # time since guessing stimuli #FIXME\n",
    "    2 + # time since guess block started #FIXME\n",
    "    1 + # time since keypress (any)\n",
    "    2 + # gender, age\n",
    "    6 + # task identifier (is_gonogo, is_(non)conscious, is_wm, is_gambling, is_hairi)\n",
    "    3 + # study identifier (conn, engage, rad)\n",
    "    1 + # is_mb\n",
    "    0\n",
    ")\n",
    "\"Number of features:\", num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cloud = Cloud()\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tasks  = \"config/tasks.json\"\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'filters' and 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-323ec44404bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-323ec44404bf>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(num_features)\u001b[0m\n\u001b[1;32m      2\u001b[0m     model = keras.Sequential([\n\u001b[1;32m      3\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'filters' and 'kernel_size'"
     ]
    }
   ],
   "source": [
    "def build_model(num_features):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation=tf.nn.relu, input_shape=(num_features, 1)),\n",
    "        layers.Conv1D(activation=tf.nn.relu),\n",
    "        layers.Dense(64, activation=tf.nn.relu),\n",
    "        layers.AveragePooling1D(pool_size=2),\n",
    "        layers.Dense(32, activation=tf.nn.relu),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mean_absolute_error', 'mean_squared_error']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Iterate over tasks\n",
    "for task in tasks:\n",
    "    task_info = tasks[task]\n",
    "    num_vols  = task_info[\"vol\"]\n",
    "    if \"project\" in task_info:\n",
    "        projects = task_info[\"project\"]\n",
    "    else:\n",
    "        projects = [\"rad\", \"connectome\", \"engage\"]\n",
    "        \n",
    "    ### Iterate over projects\n",
    "    for project in projects:\n",
    "        time_sessions = project_config[\"time_sessions\"]\n",
    "        subjects = load_project_subjects(project)\n",
    "        \n",
    "        ### Iterate over time_session/subject\n",
    "        for time_session in time_sessions:\n",
    "            for subject in subjects:\n",
    "                ### Set logger info\n",
    "                logger.set(project=project, subject=subject, time_session=time_session, task=task)\n",
    "            \n",
    "                ### Load necessary data\n",
    "                patient    = Patient(project, subject, time_session)\n",
    "                dicom_path = cloud.download(project, subject, time_session, task)\n",
    "                button     = Button(project, subject, time_session, task)\n",
    "                \n",
    "                ### Check all data exists\n",
    "                if not _valid_patient(patient, dicom_path, button, logger):\n",
    "                    continue\n",
    "                    \n",
    "                ### More setup\n",
    "                fmri_data = DicomDir(dicom_path)\n",
    "                fmri_data.cut_volumes(fmri_data.num_volumes - num_vols)\n",
    "                \n",
    "                ### Modeling\n",
    "                model.load(model_path)\n",
    "                model.run(patient, fmri_data, button)\n",
    "                model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
