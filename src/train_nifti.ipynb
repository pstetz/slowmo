{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grey masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_001716': 1, 'in_013136': 0, 'in_073720': 0, 'in_125909': 0, 'in_131520': 0, 'in_156999': 0, 'in_176064': 0, 'in_182355': 0, 'in_216192': 0, 'in_275836': 0, 'in_291082': 0, 'in_414207': 0, 'in_426426': 0, 'in_447647': 0, 'in_450767': 0, 'in_477522': 0, 'in_525931': 0, 'in_532911': 0, 'in_533294': 0, 'in_534482': 0, 'in_707656': 0, 'in_752691': 0, 'in_779062': 0, 'in_791103': 0, 'in_831650': 0, 'in_877949': 0, 'in_911981': 0, 'in_954861': 0}\n"
     ]
    }
   ],
   "source": [
    "masks = glob(\"/Volumes/hd_4tb/masks/plip/*\")\n",
    "masks = [{\n",
    "    \"code\": os.path.basename(mask).split(\"_\")[0],\n",
    "    \"data\": nib.load(mask).get_data(),\n",
    "} for mask in masks]\n",
    "\n",
    "def _in_mask(masks, x, y, z):\n",
    "    result = dict()\n",
    "    for mask in masks:\n",
    "        code = mask[\"code\"]\n",
    "        data = mask[\"data\"]\n",
    "        result[\"in_%s\" % code] = int(bool(data[x, y, z]))\n",
    "    return result\n",
    "\n",
    "def _mean_activation(masks, fmri, grey, t, label):\n",
    "    activations = dict()\n",
    "    for mask in masks:\n",
    "        code, data = mask[\"code\"], mask[\"data\"]\n",
    "        region = np.multiply(data, fmri[:, :, :, t])\n",
    "        activations[\"mean_%s_%s\" % (code, label)] = np.mean( np.multiply(grey, region) )\n",
    "    return activations\n",
    "\n",
    "def _mask_info(masks, fmri, grey, coord):\n",
    "    x, y, z, t = coord\n",
    "    info = _in_mask(masks, x, y, z)\n",
    "    for timepoint, label in [(t-1, \"prev\"), (t+1, \"next\")]:\n",
    "        info = {**info, **_mean_activation(masks, fmri, grey, timepoint, label)}\n",
    "    return info\n",
    "\n",
    "print(_in_mask(masks, 49, 66, 33))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_volume(fmri, x, y, z, t):\n",
    "    volume = nii_input(fmri[:, :, :, t], x, y, z)\n",
    "    return np.array(volume)\n",
    "\n",
    "def _load(filepath):\n",
    "    return nib.as_closest_canonical(nib.load(filepath))\n",
    "\n",
    "def _get_data(filepath):\n",
    "    image = _load(filepath)\n",
    "    return image.get_data()\n",
    "\n",
    "def _time_map(session):\n",
    "    _map = {\n",
    "        \"s1\": \"000\", \"s2\": \"2MO\", \"s3\": \"6MO\", \"s4\": \"12MO\", \"s5\": \"24MO\"\n",
    "    }\n",
    "    return _map[session]\n",
    "\n",
    "def _get(row, item):\n",
    "    return row[item]\n",
    "\n",
    "def _fmri_path(row):\n",
    "    _input = \"/Volumes/hd_4tb/raw\"\n",
    "    project = _get(row, \"project\")\n",
    "    subject = _get(row, \"subject\")\n",
    "    time_session = _get(row, \"time_session\")\n",
    "    task = _get(row, \"task\")\n",
    "    return join(_input, project, _time_map(time_session), subject, task)\n",
    "\n",
    "def nii_input(data, x, y, z, r = 4):\n",
    "    return data[\n",
    "        x - r : x + r + 1,\n",
    "        y - r : y + r + 1,\n",
    "        z - r : z + r + 1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onset_time(onsets, curr_time):\n",
    "    onset = onsets[onsets[\"ons\"] < curr_time]\n",
    "    onset = onset.sort_values(\"ons\", ascending=False)\n",
    "    if len(onset) > 0:\n",
    "        _time = onset.iloc[0].ons\n",
    "        return curr_time - _time\n",
    "    return False\n",
    "\n",
    "def _stim_time(df, stimuli, curr_time):\n",
    "    stim = df[df.category == stimuli]\n",
    "    return _onset_time(stim, curr_time)\n",
    "\n",
    "def _keypress_times(df, button, curr_time):\n",
    "    keys = df[(\n",
    "        (df[\"category\"] == \"keypress\") &\n",
    "        (df[\"stimulus\"] == button)\n",
    "    )]\n",
    "    return _onset_time(keys, curr_time)\n",
    "\n",
    "def last_onset(onset_df, task, curr_time, max_time=1000):\n",
    "    task_stimuli = {\n",
    "        \"gonogo\":       [\"Go\", \"NoGo\"],\n",
    "        \"conscious\":    [\"Anger\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\"],\n",
    "        \"nonconscious\": [\"Anger\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\"],\n",
    "        \"workingmemSB\": [\"Baseline\", \"NonTarget\", \"Target\"],\n",
    "        \"workingmemMB\": [\"Baseline\", \"NonTarget\", \"Target\"],\n",
    "    }\n",
    "    all_stimuli  = set(np.concatenate(list(task_stimuli.values())))\n",
    "    onset_timing = {stimuli: max_time for stimuli in all_stimuli}\n",
    "    for button in [\"1\", \"6\"]:\n",
    "        onset_timing[button] = _keypress_times(onset_df, button, curr_time)\n",
    "        \n",
    "    for stimuli in task_stimuli[task]:\n",
    "        _time = _stim_time(onset_df, stimuli, curr_time)\n",
    "        if _time:\n",
    "            onset_timing[stimuli] = _time\n",
    "    return pd.DataFrame(onset_timing, index=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Add mean mask activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _checkpoint():\n",
    "    return False\n",
    "\n",
    "def _load_model():\n",
    "    info_input = keras.Input(shape=(126,), name=\"info\")\n",
    "    prev_input = keras.Input(shape=(9, 9, 9, 2), name=\"prev\")\n",
    "    next_input = keras.Input(shape=(9, 9, 9, 2), name=\"next\")\n",
    "\n",
    "    prev_conv1 = layers.Conv3D(1, (2, 2, 2))(prev_input)\n",
    "    next_conv1 = layers.Conv3D(1, (2, 2, 2))(next_input)\n",
    "    prev_conv2 = layers.Conv3D(4, (2, 2, 2))(prev_conv1)\n",
    "    next_conv2 = layers.Conv3D(4, (2, 2, 2))(next_conv1)\n",
    "    \n",
    "    info      = layers.Dense(126)(info_input)\n",
    "    flat_prev = layers.Flatten()(prev_conv2)\n",
    "    flat_next = layers.Flatten()(next_conv2)\n",
    "\n",
    "    x_0 = layers.concatenate([flat_prev, flat_next, info])\n",
    "    x_1 = layers.Dense(812)(x_0)\n",
    "    x_2 = layers.Dense(812)(x_1)\n",
    "    x_3 = layers.Dense(812)(x_2)\n",
    "    x_4 = layers.Dense(406)(x_3)\n",
    "    x_5 = layers.Dense(203)(x_4)\n",
    "    x_6 = layers.Dense(203)(x_5)\n",
    "    x_7 = layers.Dense(100)(x_6)\n",
    "    x_8 = layers.Dense( 50)(x_7)\n",
    "    bold_signal = layers.Dense(1, activation=\"sigmoid\", name=\"bold_signal\")(x_8)\n",
    "\n",
    "    model = keras.Model(inputs=[prev_input, next_input, info_input], outputs=[bold_signal])\n",
    "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.00001),\n",
    "          loss={\"bold_signal\": \"mean_squared_error\"},\n",
    "          loss_weights=[1.])\n",
    "#     if _checkpoint():\n",
    "#         model.load_weights(\"checkpoint_path\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df                = pd.read_csv(\"/Volumes/hd_4tb/project/model_input.csv\")\n",
    "available_volumes = np.load(\"available_volumes.npy\")\n",
    "train_cols        = [c for c in df.columns if c.startswith(\"is_\")] + [\"age\"]\n",
    "model = _load_model()\n",
    "batch_size  = 128\n",
    "num_epoches = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "For working with multiple inputs/outputs see [here](https://www.tensorflow.org/guide/keras/functional#models_with_multiple_inputs_and_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  1,   2,   3, ..., 148, 149, 150],\n",
       "        [  1,   2,   3, ..., 148, 149, 150],\n",
       "        [  1,   2,   3, ..., 148, 149, 150],\n",
       "        ...,\n",
       "        [  1,   2,   3, ..., 148, 149, 150],\n",
       "        [  1,   2,   3, ..., 148, 149, 150],\n",
       "        [  1,   2,   3, ..., 148, 149, 150]]),\n",
       " array([[ 9,  9,  9, ...,  9,  9,  9],\n",
       "        [46, 46, 46, ..., 46, 46, 46],\n",
       "        [34, 34, 34, ..., 34, 34, 34],\n",
       "        ...,\n",
       "        [80, 80, 80, ..., 80, 80, 80],\n",
       "        [53, 53, 53, ..., 53, 53, 53],\n",
       "        [30, 30, 30, ..., 30, 30, 30]])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.meshgrid(np.array(range(1, fmri.shape[3])), available_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian(data, timepoints):\n",
    "    ret = list()\n",
    "    for x, y, z in tqdm(data):\n",
    "        for t in timepoints:\n",
    "            ret.append((x, y, z, t))\n",
    "    return np.array(ret)\n",
    "\n",
    "cartesian( available_volumes, np.array(range(1, fmri.shape[3]))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ea9881c4c147acb2761e19e8ae1ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-33fe463b2a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtraining_voxels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable_volumes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_voxels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0monsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_onset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monset_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"task\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0monsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0monsets\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    TR = 2 if _get(row, \"is_mb\") == 0 else 0.71\n",
    "    fmri_path = _fmri_path(row)\n",
    "    fmri      = _get_data(join(fmri_path, \"normalized.nii.gz\"))\n",
    "    grey      = _get_data(join(fmri_path, \"..\", \"structural\", \"gm_probseg.nii.gz\"))\n",
    "    onset_df  = pd.read_csv(join(fmri_path, \"onsets.csv\"))\n",
    "    info = pd.concat([pd.DataFrame(row[train_cols]).T] * batch_size).reset_index(drop=True)\n",
    "    \n",
    "    batch = {\"prev\": list(), \"next\": list()}\n",
    "    bold_signal, mask_rows = list(), list()\n",
    "    training_voxels = np.meshgrid(np.linspace(1, fmri.shape[3]), available_volumes)\n",
    "\n",
    "    for x, y, z, t in tqdm(training_voxels):\n",
    "        onsets = last_onset(onset_df, _get(row, \"task\"), TR * t, max_time=1000)\n",
    "        onsets = pd.concat([onsets] * batch_size).reset_index(drop=True)\n",
    "        if len(batch[\"prev\"]) == batch_size:\n",
    "            batch[\"info\"] = pd.concat([\n",
    "                onsets, info, pd.DataFrame(mask_rows)\n",
    "            ], axis=1)\n",
    "            batch[\"prev\"], batch[\"next\"] = np.array(batch[\"prev\"]), np.array(batch[\"next\"])\n",
    "            model.fit(\n",
    "                batch, {'bold_signal': np.array(bold_signal)},\n",
    "                epochs=num_epoches, batch_size=8\n",
    "            )\n",
    "            batch = {\"prev\": list(), \"next\": list()}\n",
    "            bold_signal, mask_rows = list(), list()\n",
    "        mask_rows.append( _mask_info(masks, fmri, grey, (x, y, z, t))  )\n",
    "        grey_data = nii_input(grey, x, y, z)\n",
    "        for name, timepoint in [(\"prev\", t-1), (\"next\", t+1)]:\n",
    "            batch[name].append(\n",
    "                np.stack((_load_volume(fmri, x, y, z, timepoint), grey_data), axis=3)\n",
    "            )\n",
    "\n",
    "        bold_signal.append(fmri[x, y, z, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
