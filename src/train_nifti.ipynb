{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard imports\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from conv4d import conv4d\n",
    "\n",
    "\n",
    "### Custom helpers\n",
    "import sys\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grey masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'001716': True, '013136': False, '073720': False, '125909': False, '131520': False, '156999': False, '176064': False, '182355': False, '216192': False, '275836': False, '291082': False, '414207': False, '426426': False, '447647': False, '450767': False, '477522': False, '525931': False, '532911': False, '533294': False, '534482': False, '707656': False, '752691': False, '779062': False, '791103': False, '831650': False, '877949': False, '911981': False, '954861': False}\n"
     ]
    }
   ],
   "source": [
    "masks = glob(\"/Volumes/hd_4tb/masks/plip/*\")\n",
    "masks = [{\n",
    "    \"code\": os.path.basename(mask).split(\"_\")[0],\n",
    "    \"data\": nib.load(mask).get_data(),\n",
    "} for mask in masks]\n",
    "\n",
    "def _in_mask(masks, x, y, z):\n",
    "    result = dict()\n",
    "    for mask in masks:\n",
    "        code = mask[\"code\"]\n",
    "        data = mask[\"data\"]\n",
    "        result[code] = bool(data[x, y, z])\n",
    "    return result\n",
    "\n",
    "print(_in_mask(masks, 49, 66, 33))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_volume(fmri, x, y, z, t):\n",
    "    volume = nii_input(fmri[:, :, :, t], x, y, z)\n",
    "    return np.array(volume)\n",
    "\n",
    "def _load(filepath):\n",
    "    return nib.as_closest_canonical(nib.load(filepath))\n",
    "\n",
    "def _get_data(filepath):\n",
    "    image = _load(filepath)\n",
    "    return image.get_data()\n",
    "\n",
    "def _time_map(session):\n",
    "    _map = {\n",
    "        \"s1\": \"000\", \"s2\": \"2MO\", \"s3\": \"6MO\", \"s4\": \"12MO\", \"s5\": \"24MO\"\n",
    "    }\n",
    "    return _map[session]\n",
    "\n",
    "def _get(row, item):\n",
    "    return row[item]\n",
    "\n",
    "def _fmri_path(row):\n",
    "    _input = \"/Volumes/hd_4tb/raw\"\n",
    "    project = _get_project(row)\n",
    "    subject = _get(row, \"subject\")\n",
    "    time_session = _get(row, \"time_session\")\n",
    "    task = _get(row, \"task\")\n",
    "    return join(_input, project, _time_map(time_session), subject, task)\n",
    "\n",
    "def nii_input(data, x, y, z, r = 2):\n",
    "    return data[\n",
    "        x - r : x + r + 1,\n",
    "        y - r : y + r + 1,\n",
    "        z - r : z + r + 1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _onset_time(onsets, curr_time):\n",
    "    onset = onsets[onsets[\"ons\"] < curr_time]\n",
    "    onset = onset.sort_values(\"ons\", ascending=False)\n",
    "    if len(onset) > 0:\n",
    "        _time = onset.iloc[0].ons\n",
    "        return curr_time - _time\n",
    "    return False\n",
    "\n",
    "def _stim_time(df, stimuli, curr_time):\n",
    "    stim = df[df.category == stimuli]\n",
    "    return _onset_time(stim, curr_time)\n",
    "\n",
    "def _keypress_times(df, button, curr_time):\n",
    "    keys = df[(\n",
    "        (df[\"category\"] == \"keypress\") &\n",
    "        (df[\"stimulus\"] == button)\n",
    "    )]\n",
    "    return _onset_time(keys, curr_time)\n",
    "\n",
    "def last_onset(onset_df, task, curr_time, max_time=1000):\n",
    "    task_stimuli = {\n",
    "        \"gonogo\":       [\"Go\", \"NoGo\"],\n",
    "        \"conscious\":    [\"Anger\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\"],\n",
    "        \"nonconscious\": [\"Anger\", \"Disgust\", \"Fear\", \"Happy\", \"Neutral\", \"Sad\"],\n",
    "        \"workingmemSB\": [\"Baseline\", \"NonTarget\", \"Target\"],\n",
    "        \"workingmemMB\": [\"Baseline\", \"NonTarget\", \"Target\"],\n",
    "    }\n",
    "    all_stimuli  = set(np.concatenate(list(task_stimuli.values())))\n",
    "    onset_timing = {stimuli: max_time for stimuli in all_stimuli}\n",
    "    for button in [\"1\", \"6\"]:\n",
    "        onset_timing[button] = _keypress_times(onset_df, button, curr_time)\n",
    "        \n",
    "    for stimuli in task_stimuli[task]:\n",
    "        _time = _stim_time(onset_df, stimuli, curr_time)\n",
    "        if _time:\n",
    "            onset_timing[stimuli] = _time\n",
    "    print(onset_timing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _checkpoint():\n",
    "    return False\n",
    "\n",
    "def _load_model():\n",
    "    next_volume = keras.Input(shape=(5, 5, 5,), name=\"next_volume\")\n",
    "    prev_volume = keras.Input(shape=(5, 5, 5,), name=\"prev_volume\")\n",
    "\n",
    "    prev_volume = layers.Conv3D()(prev_volume)\n",
    "#     prev_volume = keras.Input(shape=(2, 5, 5, 5,), name=\"prev_volume\")\n",
    "#     info        = keras.Input(shape=(42,), name=\"info\")\n",
    "    \n",
    "# #     title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# #     body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "#     x = layers.concatenate([prev_volume, next_volume, info])\n",
    "\n",
    "#     bold_signal = layers.Dense(1, activation=\"sigmoid\", name=\"bold_signal\")(x)\n",
    "\n",
    "#     model = keras.Model(inputs=[prev_volume, next_volume, info], outputs=[bold_signal])\n",
    "#     model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "#           loss={\"bold_signal\": 'binary_crossentropy'},\n",
    "#           loss_weights=[1.])\n",
    "#     if _checkpoint():\n",
    "#         model.load_weights(\"checkpoint_path\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-abe901e59713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-bb0d25f7be12>\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgrey_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grey_volume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprev_volume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrey_volume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#     prev_volume = keras.Input(shape=(2, 5, 5, 5,), name=\"prev_volume\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     info        = keras.Input(shape=(42,), name=\"info\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "_load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "For working with multiple inputs/outputs see [here](https://www.tensorflow.org/guide/keras/functional#models_with_multiple_inputs_and_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 2, 5, 5, 5), (None, 2, 5, 5, 5), (None, 29), (None, 13)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-3e211013a6f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mavailable_volumes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"available_volumes.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_cols\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-132-039a9092b3c2>\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     body_features = layers.Embedding(num_words, 64)(body_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprev_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_volume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monsets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbold_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bold_signal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \"\"\"\n\u001b[0;32m--> 687\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    389\u001b[0m                        \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                        \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                        'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 2, 5, 5, 5), (None, 2, 5, 5, 5), (None, 29), (None, 13)]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "df                = pd.read_csv(\"/Volumes/hd_4tb/project/model_input.csv\")\n",
    "available_volumes = np.load(\"available_volumes.npy\")\n",
    "train_cols        = [c for c in df.columns if c.startswith(\"is_\")] + [\"age\"]\n",
    "model = _load_model()\n",
    "batch_size = 64\n",
    "\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    TR = 2 if _get(row, \"is_mb\") == 0 else 0.71\n",
    "    fmri_path = _fmri_path(row)\n",
    "    fmri      = _get_data(join(fmri_path, \"normalized.nii.gz\"))\n",
    "    grey      = _get_data(join(fmri_path, \"..\", \"structural\", \"gm_probseg.nii.gz\"))\n",
    "    onset_df  = pd.read_csv(join(fmri_path, \"onsets.csv\"))\n",
    "    info      = row[train_colsa]\n",
    "    \n",
    "    batch = {\"prev_volume\": list(), \"next_volume\": list()}\n",
    "    bold_sigal = list()\n",
    "    for t in range(1, fmri.shape[3]):\n",
    "        onsets = last_onset(onset_df, _get(row, \"task\"), TR * t, max_time=1000)\n",
    "        for x, y, z in tqdm(available_volumes):\n",
    "            if len(batch[\"prev_volume\"]) == batch_size:\n",
    "                batch[\"info\"] = pd.concat([\n",
    "                    pd.concat([onsets] * batch_size),\n",
    "                    pd.concat([info] * batch_size)\n",
    "                ], axis=1)\n",
    "                print(batch[\"info\"].shape)\n",
    "                model.fit(\n",
    "                    batch, {'priority': bold_signal},\n",
    "                    epochs=2, batch_size=32\n",
    "                )\n",
    "                batch = {\"prev_volume\": list(), \"next_volume\": list()}\n",
    "                bold_signal = list()\n",
    "            \n",
    "            grey_data = nii_input(grey, x, y, z)\n",
    "            batch[\"prev_volume\"].append(np.multiply(grey_data, _load_volume(fmri, x, y, z, t-1)))\n",
    "            batch[\"next_volume\"].append(np.multiply(grey_data, _load_volume(fmri, x, y, z, t+1)))\n",
    "            bold_signal.append(fmri[x, y, z, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
